{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0428,  0.2412]]])\n"
     ]
    }
   ],
   "source": [
    "# One hot encoding for each char in 'hello'\n",
    "h = [1, 0, 0, 0]\n",
    "e = [0, 1, 0, 0]\n",
    "l = [0, 0, 1, 0]\n",
    "o = [0, 0, 0, 1]\n",
    "\n",
    "#One cell RNN input_dim (4) -> output_dim (2). sequence: 5\n",
    "cell = nn.RNN(input_size=4, hidden_size=2, batch_first=True)\n",
    "\n",
    "# (num_layers * num_directions, batch, hidden_size) whether batch_first=True or False\n",
    "hidden = Variable(torch.randn(1,1,2))\n",
    "\n",
    "print(hidden.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Propagate input through RNN\n",
    "# Input: (batch, seq_len, input_size) when batch_first=True\n",
    "inputs = Variable(torch.Tensor([h,e,l,l,o]))\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 0., 0., 0.]]])\n",
      "one input size  torch.Size([1, 1, 4]) \n",
      "out size:  torch.Size([1, 1, 2])\n",
      "out:  tensor([[[0.4459, 0.6955]]], grad_fn=<TransposeBackward0>)\n",
      "hidden:  tensor([[[0.4459, 0.6955]]], grad_fn=<StackBackward>)\n",
      "tensor([[[0., 1., 0., 0.]]])\n",
      "one input size  torch.Size([1, 1, 4]) \n",
      "out size:  torch.Size([1, 1, 2])\n",
      "out:  tensor([[[0.8065, 0.4371]]], grad_fn=<TransposeBackward0>)\n",
      "hidden:  tensor([[[0.8065, 0.4371]]], grad_fn=<StackBackward>)\n",
      "tensor([[[0., 0., 1., 0.]]])\n",
      "one input size  torch.Size([1, 1, 4]) \n",
      "out size:  torch.Size([1, 1, 2])\n",
      "out:  tensor([[[0.9688, 0.7976]]], grad_fn=<TransposeBackward0>)\n",
      "hidden:  tensor([[[0.9688, 0.7976]]], grad_fn=<StackBackward>)\n",
      "tensor([[[0., 0., 1., 0.]]])\n",
      "one input size  torch.Size([1, 1, 4]) \n",
      "out size:  torch.Size([1, 1, 2])\n",
      "out:  tensor([[[0.9844, 0.7846]]], grad_fn=<TransposeBackward0>)\n",
      "hidden:  tensor([[[0.9844, 0.7846]]], grad_fn=<StackBackward>)\n",
      "tensor([[[0., 0., 0., 1.]]])\n",
      "one input size  torch.Size([1, 1, 4]) \n",
      "out size:  torch.Size([1, 1, 2])\n",
      "out:  tensor([[[0.9797, 0.7410]]], grad_fn=<TransposeBackward0>)\n",
      "hidden:  tensor([[[0.9797, 0.7410]]], grad_fn=<StackBackward>)\n"
     ]
    }
   ],
   "source": [
    "for one in inputs:\n",
    "    one = one.view(1,1,-1)\n",
    "    print(one)\n",
    "    out,hidden = cell(one,hidden)\n",
    "    print(\"one input size \", one.size(), \"\\nout size: \",out.size())\n",
    "    print(\"out: \",out)\n",
    "    print(\"hidden: \",hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence input size torch.Size([1, 5, 4]) out size torch.Size([1, 1, 2])\n",
      "out:  tensor([[[0.9783, 0.7415]]], grad_fn=<TransposeBackward0>)\n",
      "hidden:  tensor([[[0.9783, 0.7415]]], grad_fn=<StackBackward>)\n"
     ]
    }
   ],
   "source": [
    "# We can do the whole at once\n",
    "# Propagate input through RNN\n",
    "# Input: (batch, seq_len, input_size) when batch_first=True\n",
    "\n",
    "inputs = inputs.view(1,5,-1)\n",
    "out,hidden = cell(one,hidden)\n",
    "print(\"sequence input size\", inputs.size(), \"out size\", out.size())\n",
    "print(\"out: \",out)\n",
    "print(\"hidden: \",hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.9220,  0.1620],\n",
      "         [ 0.3504,  0.1072],\n",
      "         [-0.7518, -0.3606]]])\n"
     ]
    }
   ],
   "source": [
    "# hidden : (num_layers * num_directions, batch, hidden_size) whether batch_first=True or False\n",
    "hidden = Variable(torch.randn(1, 3, 2))\n",
    "print(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1.]],\n",
      "\n",
      "        [[0., 1., 0., 0.],\n",
      "         [0., 0., 0., 1.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 1., 0.]],\n",
      "\n",
      "        [[0., 0., 1., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0.]]])\n",
      "tensor([[[0.9797, 0.7410],\n",
      "         [0.9844, 0.7835],\n",
      "         [0.9661, 0.7967]]], grad_fn=<StackBackward>)\n",
      "batch input size torch.Size([3, 5, 4]) out size torch.Size([3, 5, 2])\n",
      "out:  tensor([[[-0.1200,  0.7755],\n",
      "         [ 0.6759,  0.5231],\n",
      "         [ 0.9675,  0.8067],\n",
      "         [ 0.9846,  0.7847],\n",
      "         [ 0.9797,  0.7410]],\n",
      "\n",
      "        [[ 0.5712,  0.4555],\n",
      "         [ 0.9474,  0.7767],\n",
      "         [ 0.9835,  0.7863],\n",
      "         [ 0.9845,  0.7835],\n",
      "         [ 0.9844,  0.7835]],\n",
      "\n",
      "        [[ 0.5026,  0.8869],\n",
      "         [ 0.9756,  0.8175],\n",
      "         [ 0.9104,  0.3475],\n",
      "         [ 0.8221,  0.3616],\n",
      "         [ 0.9661,  0.7967]]], grad_fn=<TransposeBackward0>)\n",
      "hidden:  tensor([[[0.9797, 0.7410],\n",
      "         [0.9844, 0.7835],\n",
      "         [0.9661, 0.7967]]], grad_fn=<StackBackward>)\n"
     ]
    }
   ],
   "source": [
    "inputs = Variable(torch.Tensor([[h,e,l,l,o],\n",
    "                                [e,o,l,l,l],\n",
    "                                [l,l,e,e,l]\n",
    "                               ]))\n",
    "print(inputs)\n",
    "# Propagate input through RNN\n",
    "# Input: (batch, seq_len, input_size) when batch_first=True\n",
    "# B x S x I\n",
    "out, hidden = cell(inputs, hidden)\n",
    "print(hidden)\n",
    "print(\"batch input size\", inputs.size(), \"out size\", out.size())\n",
    "print(\"out: \",out)\n",
    "print(\"hidden: \",hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 0., 0., 0.],\n",
      "         [0., 1., 0., 0.],\n",
      "         [0., 0., 1., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0.],\n",
      "         [0., 0., 0., 1.],\n",
      "         [0., 0., 1., 0.]],\n",
      "\n",
      "        [[0., 0., 1., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 1., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 1., 0.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 1., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 1.],\n",
      "         [0., 0., 1., 0.],\n",
      "         [0., 0., 1., 0.]]])\n",
      "batch input size torch.Size([5, 3, 4]) out size torch.Size([5, 3, 2])\n",
      "out:  tensor([[[-0.0198,  0.7311],\n",
      "         [-0.4763,  0.5800],\n",
      "         [ 0.4422,  0.4770]],\n",
      "\n",
      "        [[-0.5306,  0.1620],\n",
      "         [-0.0765,  0.0337],\n",
      "         [ 0.3103,  0.0754]],\n",
      "\n",
      "        [[ 0.1444, -0.5178],\n",
      "         [ 0.1174, -0.4162],\n",
      "         [-0.6828, -0.0940]],\n",
      "\n",
      "        [[-0.0894, -0.5955],\n",
      "         [-0.0506, -0.5614],\n",
      "         [-0.7412, -0.5793]],\n",
      "\n",
      "        [[-0.4804, -0.4803],\n",
      "         [-0.1165, -0.6662],\n",
      "         [-0.1585, -0.8129]]], grad_fn=<StackBackward>)\n",
      "hidden:  tensor([[[-0.4804, -0.4803],\n",
      "         [-0.1165, -0.6662],\n",
      "         [-0.1585, -0.8129]]], grad_fn=<StackBackward>)\n"
     ]
    }
   ],
   "source": [
    "# One cell RNN input_dim (4) -> output_dim (2)\n",
    "cell = nn.RNN(input_size=4, hidden_size=2)\n",
    "\n",
    "# The given dimensions dim0 and dim1 are swapped.\n",
    "inputs = inputs.transpose(dim0=0, dim1=1)\n",
    "print(inputs)\n",
    "# Propagate input through RNN\n",
    "# Input: (seq_len, batch_size, input_size) when batch_first=False (default)\n",
    "# S x B x I\n",
    "out, hidden = cell(inputs, hidden)\n",
    "print(\"batch input size\", inputs.size(), \"out size\", out.size())\n",
    "print(\"out: \",out)\n",
    "print(\"hidden: \",hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
