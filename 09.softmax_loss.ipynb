{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1 =  0.35667494393873245\n",
      "loss2 =  2.3025850929940455\n"
     ]
    }
   ],
   "source": [
    "# One hot\n",
    "# 0: 1 0 0\n",
    "# 1: 0 1 0\n",
    "# 2: 0 0 1\n",
    "Y = np.array([1, 0, 0])\n",
    "\n",
    "Y_pred1 = np.array([0.7, 0.2, 0.1])\n",
    "Y_pred2 = np.array([0.1, 0.3, 0.6])\n",
    "\n",
    "print(\"loss1 = \", np.sum(-Y * np.log(Y_pred1)))\n",
    "print(\"loss2 = \", np.sum(-Y * np.log(Y_pred2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Loss1 =  tensor(0.4170) \n",
      "PyTorch Loss2= tensor(1.8406)\n",
      "Y_pred1 =  tensor([0])\n",
      "Y_pred2 =  tensor([1])\n"
     ]
    }
   ],
   "source": [
    "#softmax + CrossEntropy(logSoftmax + NLLLoss)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "#target is of size nBatch\n",
    "#each element in target has to have 0\n",
    "#input is class, not one-hot\n",
    "\n",
    "Y = Variable(torch.LongTensor([0]), requires_grad = False)\n",
    "\n",
    "#input is of size nBatch x nClasses = 1 x 4\n",
    "# Y_pred are logits (not softmax)\n",
    "Y_pred1 = Variable(torch.Tensor([[2.0,1.0,0.1]]))\n",
    "Y_pred2 = Variable(torch.Tensor([[0.5,2.0,0.3]]))\n",
    "\n",
    "l1 = loss(Y_pred1,Y)\n",
    "l2 = loss(Y_pred2,Y)\n",
    "\n",
    "print(\"PyTorch Loss1 = \", l1.data, \"\\nPyTorch Loss2=\", l2.data)\n",
    "print('Y_pred1 = ', torch.max(Y_pred1.data, 1)[1])\n",
    "print('Y_pred2 = ', torch.max(Y_pred2.data, 1)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss1 =  tensor(0.4966) \n",
      "Batch Loss2= tensor(1.2389)\n"
     ]
    }
   ],
   "source": [
    "#target\n",
    "\n",
    "Y = Variable(torch.LongTensor([2,0,1]), requires_grad = False)\n",
    "\n",
    "#input is of size nbatch\n",
    "Y_pred1 = Variable(torch.Tensor([[0.1,0.2,0.9],\n",
    "                                 [1.1,0.1,0.2],\n",
    "                                 [0.2,2.1,0.1]]))\n",
    "Y_pred2 = Variable(torch.Tensor([[0.8,0.2,0.3],\n",
    "                                 [0.2,0.3,0.5],\n",
    "                                 [0.2,0.2,0.5]]))\n",
    "\n",
    "l1 = loss(Y_pred1,Y)\n",
    "l2 = loss(Y_pred2,Y)\n",
    "print(\"Batch Loss1 = \", l1.data, \"\\nBatch Loss2=\", l2.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
